{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17cc7fc6-7c58-4f73-9aab-0abd15bf8c92",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "executionInfo": {
     "elapsed": 418,
     "status": "ok",
     "timestamp": 1715956529143,
     "user": {
      "displayName": "Telma Giovana",
      "userId": "04578907977644490290"
     },
     "user_tz": -60
    },
    "id": "17cc7fc6-7c58-4f73-9aab-0abd15bf8c92",
    "outputId": "66ed868a-9db3-4a94-98cf-24a9d90841a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 165 entries, 0 to 164\n",
      "Data columns (total 50 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   Gender          165 non-null    object \n",
      " 1   Symptoms        147 non-null    object \n",
      " 2   Alcohol         165 non-null    object \n",
      " 3   HBsAg           148 non-null    object \n",
      " 4   HBeAg           126 non-null    object \n",
      " 5   HBcAb           141 non-null    object \n",
      " 6   HCVAb           156 non-null    object \n",
      " 7   Cirrhosis       165 non-null    object \n",
      " 8   Endemic         126 non-null    object \n",
      " 9   Smoking         124 non-null    object \n",
      " 10  Diabetes        162 non-null    object \n",
      " 11  Obesity         155 non-null    object \n",
      " 12  Hemochro        142 non-null    object \n",
      " 13  AHT             162 non-null    object \n",
      " 14  CRI             163 non-null    object \n",
      " 15  HIV             151 non-null    object \n",
      " 16  NASH            143 non-null    object \n",
      " 17  Varices         113 non-null    object \n",
      " 18  Spleno          150 non-null    object \n",
      " 19  PHT             154 non-null    object \n",
      " 20  PVT             162 non-null    object \n",
      " 21  Metastasis      161 non-null    object \n",
      " 22  Hallmark        163 non-null    object \n",
      " 23  Age             165 non-null    int64  \n",
      " 24  Grams_day       117 non-null    float64\n",
      " 25  Packs_year      112 non-null    float64\n",
      " 26  PS              165 non-null    object \n",
      " 27  Encephalopathy  164 non-null    object \n",
      " 28  Ascites         163 non-null    object \n",
      " 29  INR             161 non-null    float64\n",
      " 30  AFP             157 non-null    float64\n",
      " 31  Hemoglobin      162 non-null    float64\n",
      " 32  MCV             162 non-null    float64\n",
      " 33  Leucocytes      162 non-null    float64\n",
      " 34  Platelets       162 non-null    float64\n",
      " 35   Albumin        159 non-null    float64\n",
      " 36  Total_Bil       160 non-null    float64\n",
      " 37  ALT             161 non-null    float64\n",
      " 38  AST             162 non-null    float64\n",
      " 39  GGT             162 non-null    float64\n",
      " 40  ALP             162 non-null    float64\n",
      " 41  TP              154 non-null    float64\n",
      " 42  Creatinine      158 non-null    float64\n",
      " 43  Nodules         163 non-null    object \n",
      " 44  Major_Dim       145 non-null    float64\n",
      " 45  Dir_Bil         121 non-null    float64\n",
      " 46  Iron            86 non-null     float64\n",
      " 47  Sat             85 non-null     float64\n",
      " 48  Ferritin        85 non-null     float64\n",
      " 49  Class           165 non-null    object \n",
      "dtypes: float64(21), int64(1), object(28)\n",
      "memory usage: 64.6+ KB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from copy import deepcopy\n",
    "\n",
    "#Carregando o dataset\n",
    "hcc = pd.read_csv(\"hcc_dataset.csv\", sep=\",\")\n",
    "\n",
    "#Ajetiando os valores nulos\n",
    "hcc.replace(np.nan, 'None', inplace=True) #Na tabela tem células com o valor None que ele interpreta como um np.nan, então precisamos garantir que ele vai entender isso como um valor válido\n",
    "hcc.replace('?', np.nan, inplace=True) #As células vazias possuem uma '?', então aqui dizemos que essas células sõa NaN\n",
    "\n",
    "for column in hcc.columns:\n",
    "    #Convertendo os valores que são numéricos para float\n",
    "    if hcc[column].dtype == 'object':\n",
    "        try:\n",
    "            if hcc[column].apply(lambda x: pd.to_numeric(x, errors='coerce')).notnull().any() and column != 'Nodules':\n",
    "                hcc[column] = pd.to_numeric(hcc[column], errors='coerce')\n",
    "        except ValueError:\n",
    "            try:\n",
    "                hcc[column] = pd.to_datetime(hcc[column], errors='coerce')\n",
    "            except ValueError:\n",
    "                pass\n",
    "\n",
    "    #Tratando os valores de texto\n",
    "    if(hcc[column].dtype == 'object'):\n",
    "        hcc[column] = hcc[column].str.upper()\n",
    "\n",
    "hcc.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad6bbf91-f5c9-4c99-bc25-d18c9c541c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoded(df, filename):\n",
    "    columns_classification = { # Colunas que tem uma ordenação\n",
    "        'PS': ['ACTIVE', 'RESTRICTED', 'AMBULATORY', 'SELFCARE', 'DISABLED'],\n",
    "        'Encephalopathy': ['NONE', 'GRADE I/II', 'GRADE III/IV'],\n",
    "        'Ascites': ['NONE', 'MILD', 'MODERATE/SEVERE']\n",
    "    }\n",
    "    \n",
    "    # Transformando as variáveis categóricas em números\n",
    "    for column in df:\n",
    "        if hcc[column].dtype == 'object' and column != 'Nodules': # se for uma variável categórica, que não seja nodules, pois esse já é numérico\n",
    "            if column in columns_classification:\n",
    "                enc = OrdinalEncoder(categories=[columns_classification[column]]).set_output(transform=\"pandas\") # vai codificar com ua ordem\n",
    "            else:\n",
    "                enc = OneHotEncoder(handle_unknown='ignore', sparse_output=False).set_output(transform=\"pandas\") # vai criar colunas de 0's e 1's\n",
    "            enc_transform = enc.fit_transform(df[[column]]) # faz a transformação da coluna codificada -> é uma nova tabela que precisa ser anexada no dataset\n",
    "    \n",
    "            # Aqui vamos considerar apenas as colunas importantes para que não seja anexada informação ambigua\n",
    "            if not(column in columns_classification or column == 'Gender' or column == 'Class'):\n",
    "                enc_transform = enc_transform.filter(regex='_YES$') # em colunas com Yes e No vamos considerar apenas o Yes, sendo ele 1 e o No 0\n",
    "            elif column == 'Gender':\n",
    "                enc_transform = enc_transform.filter(regex='_MALE$') # Como só tem 2 opção vamos considerar a coluna apenas dos homens, sendo para homem 1 e mulher 0\n",
    "            elif column == 'Class':\n",
    "                enc_transform = enc_transform.filter(regex='_LIVES$') # Como só tem 2 opção vamos considerar a coluna apenas das pessoas que sobreviveram, sendo para viver 1 e morrer 0\n",
    "            df = df.drop(columns = [column]) # excluindo a coluna que originou a codificação, exenplo (Class)\n",
    "            df = pd.concat([df, enc_transform], axis=1) # adicionando a codificação ao dataset\n",
    "    \n",
    "    df.to_csv(filename, index=False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1dfc690-2bbb-47c2-b6b3-d0737aee1589",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tratando os valores de texto -  colocando para UPPERCASE e colocando algum valor nas células vazias\n",
    "encoded_hcc = deepcopy(hcc)\n",
    "for column in encoded_hcc:\n",
    "    if(encoded_hcc[column].dtype == 'object'):\n",
    "        value = encoded_hcc[column].value_counts().idxmax() # para variáveis categóricas colocamos o valor mais frequente\n",
    "    else:\n",
    "        value = encoded_hcc[column].mean() # para valores numéricos colocamos a média\n",
    "    encoded_hcc[column].replace(np.nan, value, inplace=True)\n",
    "encoded_hcc = encoded(encoded_hcc, \"default_imputation.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad7d8623-1724-4ca2-9b5c-735395671ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "encoded_knn = deepcopy(hcc)\n",
    "label_encoders = {}\n",
    "\n",
    "# Codificando variáveis categóricas\n",
    "for column in encoded_knn:\n",
    "    if(hcc[column].dtype == 'object'):\n",
    "        label_encoders[column] = LabelEncoder()\n",
    "        encoded_knn[column] = label_encoders[column].fit_transform(hcc[column].astype(str))\n",
    "        if hcc[column].isna().any():\n",
    "            nan_encoded = label_encoders[column].transform(['nan'])[0]\n",
    "            encoded_knn[column] = encoded_knn[column].replace(nan_encoded, np.nan)\n",
    "    \n",
    "# Aplicando k-NN Imputation\n",
    "knn_imputer = KNNImputer()\n",
    "hcc_imputed_array = knn_imputer.fit_transform(encoded_knn)\n",
    "\n",
    "# Convertendo de volta para DataFrame\n",
    "hcc_imputed = pd.DataFrame(hcc_imputed_array, columns=encoded_knn.columns)\n",
    "\n",
    "# Decodificando variáveis categóricas de volta aos valores originais\n",
    "for column in encoded_knn:\n",
    "    if(hcc[column].dtype == 'object'):\n",
    "        hcc_imputed[column] = hcc_imputed[column].round().astype(int)\n",
    "        hcc_imputed[column] = label_encoders[column].inverse_transform(hcc_imputed[column])\n",
    "\n",
    "hcc_imputed = encoded(hcc_imputed, \"knn_imputation.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mavqQTVx_hKZ",
   "metadata": {
    "id": "mavqQTVx_hKZ"
   },
   "source": [
    "**DADOS ESCALONADOS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "DD-858GS0L7Q",
   "metadata": {
    "executionInfo": {
     "elapsed": 270,
     "status": "ok",
     "timestamp": 1715956541367,
     "user": {
      "displayName": "Telma Giovana",
      "userId": "04578907977644490290"
     },
     "user_tz": -60
    },
    "id": "DD-858GS0L7Q"
   },
   "outputs": [],
   "source": [
    "def escalonamento(df, filename):\n",
    "    colunas_numericas = df.select_dtypes(include=['int', 'float']).columns\n",
    "    scaler = MinMaxScaler()\n",
    "    colunas_nao_numericas = df.select_dtypes(exclude=['int', 'float']).columns\n",
    "    dados_escalados_numericos=scaler.fit_transform(df[colunas_numericas])\n",
    "    dados_escalados_numericos=pd.DataFrame(dados_escalados_numericos,columns=colunas_numericas)\n",
    "    dados_escalados = pd.concat([dados_escalados_numericos, df[colunas_nao_numericas]], axis=1)\n",
    "    df.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "AVVwjrwQ0Syh",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 443
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1715869927107,
     "user": {
      "displayName": "Telma Giovana",
      "userId": "04578907977644490290"
     },
     "user_tz": -60
    },
    "id": "AVVwjrwQ0Syh",
    "outputId": "e64414fa-e15e-496c-8fc4-6805a5e93a43"
   },
   "outputs": [],
   "source": [
    "escalonamento(encoded_hcc, \"esc_def_hcc.csv\")\n",
    "escalonamento(hcc_imputed, \"esc_knn_hcc.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2036ed-c723-4d04-b2aa-0ffd28160fa4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
